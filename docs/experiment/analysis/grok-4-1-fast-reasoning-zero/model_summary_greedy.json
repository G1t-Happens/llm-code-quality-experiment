{
  "TP": 27,
  "FP": 1,
  "FN": 18,
  "Precision": 0.9643,
  "Recall": 0.6,
  "F1": 0.7397,
  "model": "grok-4-1-fast-reasoning-zero",
  "evaluation_type": "greedy_1to1_best_semantic",
  "total_runs": 3,
  "total_TP": 27,
  "total_FP": 1,
  "total_FN": 18,
  "total_ground_truth": 15,
  "per_run_details": [
    {
      "TP": 9,
      "FP": 0,
      "FN": 6,
      "Precision": 1.0,
      "Recall": 0.6,
      "F1": 0.75,
      "run_name": "grok-4-1-fast-reasoning-zero_fault_bugs_20251209_125224_2686ac4d45b5",
      "total_predictions": 9,
      "total_ground_truth": 15
    },
    {
      "TP": 9,
      "FP": 1,
      "FN": 6,
      "Precision": 0.9,
      "Recall": 0.6,
      "F1": 0.72,
      "run_name": "grok-4-1-fast-reasoning-zero_fault_bugs_20251209_125317_2686ac4d45b5",
      "total_predictions": 10,
      "total_ground_truth": 15
    },
    {
      "TP": 9,
      "FP": 0,
      "FN": 6,
      "Precision": 1.0,
      "Recall": 0.6,
      "F1": 0.75,
      "run_name": "grok-4-1-fast-reasoning-zero_fault_bugs_20251209_125411_2686ac4d45b5",
      "total_predictions": 9,
      "total_ground_truth": 15
    }
  ]
}